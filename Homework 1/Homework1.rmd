---
title: "Homework 1"
author: "Emily Robinson"
date: "September 5, 2019"
output:
  pdf_document:
    keep_tex:  true
subtitle: STAT 984
theme: cerulean
fontsize: 12pt
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsthm}
---

<style type="text/css">

h1.title {
  font-size: 18px;
  color: Black;
  text-align: center;
}
h3.subtitle{
  font-size: 12px;
  color: Black;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
  font-size: 12px;
  font-family: "Times New Roman", Times, serif;
  color: Black;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 12px;
  font-family: "Times New Roman", Times, serif;
  color: Black;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=5, fig.height=4, fig.align = "center")
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

### Exercise 1.1
Assume that $a_n \rightarrow a$ and $b_n \rightarrow b$, where $a$ and $b$ are real numbers.

a. Prove that $a_nb_n \rightarrow ab$.

\begin{proof}
Let $a_n$ and $b_n$ be sequences and suppose $a_n \rightarrow a$ and $b_n \rightarrow b$ for real numbers $a$ and $b$. Then $\{a_n\}_{n\ge1}$ and $\{b_n\}_{n\ge1}$ are bounded.Thus, there exists an $M>0$ such that $|a_n|\le M$ for all $n\ge 1$. Consider two cases: $b=0$ and $b\ne 0$.

Case 1: Let $b = 0$. By definition of convergence (Definition 1.1), there exists some $N_1>0$ such that for all $n\ge N_1$, $|b_n-b|<\frac{\epsilon}{M}.$ Then
\begin{align*}
|a_nb_n-ab| & = |a_nb_n-a_nb+a_b-ab|\\
& = |a_n(b_n-b)+b(a_n-a)|\\
& \le |a_n(b_n-b)| +|b(a_n-a)|\\
& =|a_n||b_n-b|+|b||a_n-a|\\
& < M\left(\frac{\epsilon}{M}\right)+0\\
& = \epsilon.
\end{align*}
Case 2: Let $b \ne 0$. Then there exists $N_2>0$ such that for all $n\ge N_2$, $|b_n-b|<\frac{\epsilon}{2M}$ and there exists $N_3>0$ such that for all $n \ge N_3$, $|a_n-a|<\frac{\epsilon}{2|b|}$. Then
\begin{align*}
|a_nb_n-ab| & = |a_nb_n-a_nb+a_b-ab|\\
& = |a_n(b_n-b)+b(a_n-a)|\\
& \le |a_n(b_n-b)| +|b(a_n-a)|\\
& =|a_n||b_n-b|+|b||a_n-a|\\
& < M\left(\frac{\epsilon}{2M}\right)+|b|\left(\frac{\epsilon}{2|b|}\right)\\
& = \epsilon.
\end{align*}
Therefore, for all $\epsilon>0$, there exists $N = max\{N_1, N_2, N_3\}$, such that for all $n\ge N,$ $|a_nb_n-ab|<\epsilon.$ Thus, $a_nb_n\rightarrow ab.$
\end{proof}

\newpage

b. Prove that if $b \ne 0$, $a_n/b_n \rightarrow a/b.$

\begin{proof}
Let $a_n$ and $b_n$ be sequences and suppose $a_n \rightarrow a$ and $b_n \rightarrow b$ for $b\ne 0.$ Let $\epsilon >0$. Consider $\epsilon_1 = \frac{\epsilon}{2}$. There exists an $N_1$ such that for all $n \ge N_1$, $|b_n - b| \le \frac{|b|}{2}.$ Therefore, $|b_n|>\frac{|b|}{2}$ which implies $\frac{1}{|b_n|}<\frac{1}{|b|/2}$. Now consider $\epsilon_2 = \frac{|b|^2\epsilon}{2}$. There exists $N_2>0$ such that for all $n>N_2$, $|b_n-b|<\frac{|b|^2\epsilon}{2}$. Let $N = max\{N_1, N_2\}$. Then for all $n\ge N,$
\begin{align*}
\left|\frac{1}{b_n}-\frac{1}{b}\right| & = \left|\frac{b-b_n}{b_nb}\right|\\
&=\left|(b-b_n)\left(\frac{1}{b_nb}\right)\right|\\
&=\left|b-b_n\right|\left|\frac{1}{b_nb}\right|\\
&=\left|b_n-b\right|\frac{1}{|b_n||b|}\\
&<\frac{|b|^2\epsilon}{2}\frac{1}{|b|^2/2}\\
&=\epsilon.
\end{align*}
Thus, $\frac{1}{b_n}\rightarrow \frac{1}{b}$. Then by part (a), 
$$\left| \frac{a_n}{b_n}-\frac{a}{b}\right|=\left|a_n\left(\frac{1}{b_n}\right)-a\left(\frac{1}{b}\right)\right|\rightarrow a\frac{1}{b}=\frac{a}{b}$$
Thus, if $b \ne 0$, $a_n/b_n \rightarrow a/b.$
\end{proof}

### Exercise 1.2
For a fixed real number c, define $a_n(c) = (1 + c/n)^n$. Then Equation (1.9) states that $a_n(c) \rightarrow \exp(c)$. A different sequence with the same limit is obtained from the power series expansion of exp(c):

$$b_n(c)=\sum_{i=0}^{n-1}\frac{c^i}{i!}$$
For each of the values $c \in {-10,-1,0.2,1,5}$, find the smallest value of $n$ such that $$|a_n(c)-\exp(c)|/\exp(c)<.01.$$ Now replace $a_n(c)$ by $b_n(c)$ and repeat. Comment on any general differences you observe between the two sequences.

\newpage 
The sequence $a_n(c)$, meets the convergence criteria at $n = \{4982,51,2,50,1241\}$ for respective values of $c$.

```{r exe_1.2_an}
ex_1.2_an <- function(c, epsilon = 0.01, maxIter){
    for (n in 1:maxIter){
    value <- (1 + c/n)^n
    Conv <- abs(value - exp(c))/exp(c)
    if(Conv < epsilon) break
  }
  return(list(c = c, value = value, Convergence = Conv < epsilon, n = n))
}

resultsFunc <- function(f, c_seq){
                        results           <- matrix(NA, length(c_seq),4)
                        colnames(results) <- c("c", "value", "Convergence", "n")
                        
                        for (k in 1:length(c_seq)){
                          c_results <- f(c = c_seq[k], epsilon = 0.01, maxIter = 10000)
                          results[k, "c"]  <- c_results$c
                          results[k, "value"] <- round(c_results$value,5)
                          results[k, "Convergence"] <- as.character(c_results$Convergence)
                          results[k, "n"] <- c_results$n
                        }
                        
                        as.data.frame(results)
                        return(results)
}

c_seq <- c(-10, -1, 0.2, 1, 5)
an_results <- resultsFunc(ex_1.2_an, c_seq)
kable(an_results)
```

\newpage

The sequence $b_n(c)$, meets the convergence criteria at $n = \{38,6,3,5,12\}$ for respective values of $c$.

```{r exe_1.2_bn}
ex_1.2_bn <- function(c, epsilon = 0.01, maxIter){
  for (n in 1:maxIter){
    i  <- seq(0,n-1,1)
    value <- sum(c^i/factorial(i))
    Conv <- abs(value - exp(c))/exp(c)
    if(Conv < epsilon) break
  }
  return(list(c = c, value = value, Convergence = Conv < epsilon, n = n))
}

bn_results <- resultsFunc(ex_1.2_bn, c_seq)
kable(bn_results)
```


### Exercise 1.3

a. Suppose that $a_k \rightarrow c$ as $k \rightarrow \infty$ for a sequence of real numbers $a_1, a_2, ...$. Prove that this implies convergence in the sense of Cesaro, which means that 
\begin{align*}
&&\frac{1}{n}\sum_{k=1}^n a_k \rightarrow c \text{ as } n \rightarrow \infty. && (1.3)
\end{align*}
    In this case, $c$ may be real or it may be $\pm\infty$.

\begin{proof}
Suppose that $a_k \rightarrow c$ as $k \rightarrow \infty$ for a sequence of real numbers $a_1, a_2,...$. Let $\epsilon > 0$. Consider three cases: $a_k \rightarrow c$, $a_k \rightarrow \infty$, and $a_k \rightarrow -\infty$. 

Case 1: Consider $a_k \rightarrow c$ where $c \in \mathbb{R}$. Then there exists an $N>0$ such that for all $k>N$, $|a_k-c|<\epsilon.$ Then 
\begin{align*}
\left|\frac{1}{n}\sum_{k = 1}^n (a_n) -c\right| & = \left|\frac{1}{n}\left(\sum_{k = 1}^n(a_k) - nc\right)\right|& \le \frac{1}{n}\sum_{k = 1}^n|a_k - c|\\
& = \frac{1}{n}\sum_{k=1}^{N}|a_k-c|+\frac{1}{n}\sum_{k=N+1}^{n}|a_k-c| &(\text{first term} \rightarrow 0 \text{ since finite sum})\\
& < \frac{1}{n}\sum_{k=N+1}^n\epsilon\\
& = \frac{n-N}{n}\epsilon\\
& < \epsilon & (\text{since} \frac{n-N}{n}<1).
\end{align*}
Thus, $\frac{1}{n}\sum_{k=1}^na_k\rightarrow c$ for $c\in \mathbb{R}.$

Case 2: Consider $a_k \rightarrow \infty$. Then for all $M>0$, there exists an $N>0$ such that $a_n>2M$ if $n\ge N$. Then
\begin{align*}
\frac{1}{n}\sum_{k=1}^n a_k &= \frac{1}{n}\sum_{k=1}^Na_k + \frac{1}{n}\sum_{k=N+1}^n a_k &(\text{first term} \rightarrow 0 \text{ since finite sum})\\
& = \frac{1}{n}\sum_{k=N+1}^n a_k\\
& = \frac{1}{n}\left(a_{N+1} + a_{N+2} + ...\right)\\
& > \frac{1}{n}\left(2M + 2M + ...\right)\\
& =\frac{2(n-N)}{n}\cdot M\\
& > M \text{ if } \frac{n-N}{n}>0.5 & \text{ (i.e. for large enough } n; n>2N). 
\end{align*}
Thus, $\frac{1}{n}\sum_{k=1}^\infty a_n \rightarrow \infty.$

Case 3: Consider $a_k \rightarrow -\infty$. A similar argument follows as to Case 2 with $a_n < -2M$.

Thus, in all three cases, we have shown that $$\frac{1}{n}\sum_{k=1}^n a_k \rightarrow c \text{ as } n \rightarrow \infty. $$
\end{proof}

b. Is the converse true? In other words, does (1.3) imply $a_k \rightarrow c$?

No, the converse is not true. Consider $a_k = (-1)^{k-1}$. Then 
$$\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{k = 1}^n a_k = \lim_{n\rightarrow\infty} \frac{1}{n}\sum_{k = 1}^n (-1)^{k-1} = \lim_{n\rightarrow\infty} \{1/1, 1/2, 2/3, 2/4, 3/5, 3/6,...\} = 1/2.$$
However, $a_k$ oscillates between 1 and -1, thus $a_k$ is divergent even though the Cesaro converges to 1/2.

### Exercise 1.5

Let $a_n = \sin n$ for $n = 1,2, ...$.

a. What is $\sup_n a_n$? Does $\max_n a_n$ exist?

The $\sup_n(a_n) = 1$ and $\max_n a_n$ does not exit.

b. What is the set of limit points of $\{a_1, a_2, ...\}$? What are $\lim\sup_n a_n$ and $\lim\inf_n a_n$? (Recall that a limit point is any point that is the limit of a subsequence $a_{k_1}, a_{k_2}, ...,$ where $k_1 < k_2 < \cdot \cdot \cdot$,)

The set of limit points is $\{\sin(1), \sin(2), ...\}$ while the $\lim\sup_n a_n = 1$ and the $\lim\inf_n a_n = -1.$

c. As usual in mathematics, we assume above that angles are measured in radians. How do the answers to (a) and (b) chnge if we use degrees instead (i.e., $a_n = \sin n^{\circ}$)?

The limit points will change to $\{\sin(1^{\circ}), \sin(2^{\circ}), ..., \sin(90^{\circ}), \sin(270^{\circ}), ..., \sin(360^{\circ})\}$ and the $max_n a_n$ will exist at $n = 90$ and $n = 270$. The $\sup(a_n), \lim\sup_n a_n,$ and $\lim\inf_n a_n$ do not change.

### Exercise 1.8

Define $F(t)$ as in Example 1.15 (and as pictured in Figure 1.1). This function is not continuous so Theorem 1.16 does not apply. That is, $a_n \rightarrow a$ does not imply that $F(a_n) \rightarrow F(a)$.

a. Give an example of a sequence $\{a_n\}$ and a real number $a$ such that $a_n \rightarrow a$ but $\lim\sup_n F(a_n) \ne F(a)$.

Let $a_n = -\frac{1}{n}.$ Then $a_n$ is an increasing sequence and $a_n \rightarrow 0.$ The limit points of $F(a_n)$ are $\{0\}.$ Thus, $\lim\sup_n F(a_n) = 0 \ne \frac{1}{2} = F(0).$

b. Change your answer to part (a) so that $a_n \rightarrow a$ and $\lim\sup_n F(a_n) = F(a)$, but $\lim_n F(a_n)$ does not exist.

Let $a_n = 1+(-1)^n\frac{1}{n}.$ Then $a_n$ jumps below and above 1 until $a_n \rightarrow 1.$ The limit points of $F(a_n)$ are $\{\frac{1}{2}, 1\}.$ Thus, $\lim\sup_n F(a_n) = 1 = F(1)$ and $\lim\inf_n F(a_n) = \frac{1}{2}.$ Then $$\lim\inf_n F(a_n) \ne \lim\sup_n F(a_n)$. Thus, $\lim_n F(a_n)$ does not exist. 

c. Explain why it is not possible to change your answer so that $a_n \rightarrow a$ and $\lim\inf_n F(a_n) = F(a)$, but $\lim_n F(a_n)$ does not exist.

It is not possible to select a sequence $a_n$ such that $a_n \rightarrow a$ and $\lim\inf_n F(a_n) = F(a)$, but $\lim_n F(a_n)$ does not exist since $F(x)$ is only right continuous at $x=0$ and $x = 1.$ Therefore, if $a_n$ is a decreasing sequence which converges to either 0 or 1, $\lim\sup_n F(a_n) = \lim\inf_n F(a_n),$ and thus, $\lim_n a_n$ exists. However, if we select $a_n$ similar to part (b) where $a_n$ oscillates above and below 0 or 1 so that $\lim_n F(a_n)$ does not exist, when $a_n$ converges to 0 or 1, $\lim\inf_n F(a_n) < F(a).$

### Exercise 1.14

The gamma function $\Gamma(x)$ is defined for positive real $x$ as
$$\Gamma(x) = \int_0^\infty t^{x-1}e^{-t}dt$$
[in fact, equation (1.14) is also valid for complex $x$ with positive real part]. The gamma function may be viewed as a continuous version of the factorial function in the sense that $\Gamma(n) = (n-1)!$ for all positive integers n. The gamma function satisfies the identity
$$\Gamma(x+1) = x\Gamma(x)$$
even for noninteger positive values of $x$. Since $\Gamma (x)$ grows very quickly as $x$ increases, it is often convenient in numerical calculations to deal with the logarithm of the gamma function, which we term the log-gamma function. The $\textit{digamma function}$ $\Psi(x)$ is defined to be the derivative of the log-gamma function; this function often arises in statistical calculations involving certain distributions that use the gamma function.

a. Apply the result of Exercise 1.13(b) using $h = 1$ to demonstrate how to obtain the approximation $$\Psi(x) \approx \frac{1}{2} log[x(x-1)]$$
for $x>2.$

    Hint: Use Identity (1.15).
    
The result from Exercise 1.13 states $f'(a) \approx \frac{f(a+x) - f(a-h)}{2h}.$ Then 
\begin{align*}
\Psi (x) &= \frac{d}{dx} log \Gamma (x)\\
& \approx \frac{1}{2} \left(\log(\Gamma(x+1) - \log\Gamma(x-1)\right) & (\text{Exercise 1.13(b)})\\
& = \frac{1}{2} \left(\log(x\Gamma(x) - \log\Gamma(x)/(x-1)\right) & (\text{from 1.15})\\
& = \frac{1}{2} \left(\log(x) + \log \Gamma (x) - \log\Gamma(x) + \log(x-1)\right)\\
& = \frac{1}{2} \left(\log(x(x-1))\right). & (1.16)
\end{align*}

b. Test Approximation (1.16) numerically for all $x$ in the interval (2, 100) by plotting the ratio of the approximation to the true $\Psi(x)$. What do you notice about the quality of the approximation? If you are using R or Splus, then `digamma(x)` gives the value of $\Psi(x)$.

The approximation does not appear to perform well for $x$ close to 2. However, the approximation performs better for larger values of $x$.

```{r exe_1.14b, message=FALSE, warning=FALSE}
x     <- seq(from = 2, to = 100, by = 0.01)
ratio <- 2*digamma(x)/log(x*(x-1))
data_1.14b <- as.data.frame(cbind(x,ratio))
library(ggplot2)
ggplot(data = data_1.14b, aes(x = x, y = ratio)) +
  geom_line() + 
  theme_minimal()
```

### Exercise 1.15
The second derivative of the log-gamma function is called the trigamma function:
$$\Psi ' (x) = \frac{d^2}{dx^2}\log\Gamma(x).$$
Like the digamma function, it often arises in statistical calculations; for example, see Exercise 1.35.

a. Using the method of Exercise 1.13(c) with $h = 1$ [that is, expanding $f(x+2h), f(x+h), f(x-h),$ and $f(x-2h)$ and then finding a linear combination that makes all but the \textit{second} derivative of the log-gamma function disappear], show how to derive the following approximation to $\Psi ' (x)$ for $x>2:$
$$\Psi '(x) \approx \frac{1}{12}\log\left[\left(\frac{x}{x-1}\right)^{15}\left(\frac{x-2}{x+1}\right)\right]$$

Let $f(x) = \log\Gamma(x).$ Then $f'(x) = \Psi(x) = \frac{d}{dx}\log\Gamma(x)$ and $f''(x) = \Psi'(x) = \frac{d^2}{dx^2}\log\Gamma(x).$ Using Taylor Series to expand:

\begin{align*}
f(x+1) & \approx f(x) + f'(x) + \frac{1}{2} f''(x) + \frac{1}{6}f'''(x) + \frac{1}{24}f''''(x)\\
f(x) & \approx f(x)\\
f(x-1) & \approx f(x) - f'(x) + \frac{1}{2} f''(x) - \frac{1}{6}f'''(x) + \frac{1}{24}f''''(x)\\
\\
f(x+2) & \approx f(x) + f'(x) + 2f''(x) + \frac{8}{6}f'''(x) + \frac{16}{24}f''''(x)\\
f(x) & \approx f(x)\\
f(x-2) & \approx f(x) - f'(x) + 2f''(x) - \frac{8}{6}f'''(x) + \frac{16}{24}f''''(x)\\
\end{align*}

Then, $f(x+1)-2f(x)+f(x-1) = f''(x)+\frac{1}{12}f''''(x)$ and $f(x+2)-2f(x)+f(x-2) = 4f''(x)+\frac{16}{12}f''''(x)$. Therefore, $$f''(x) \approx \frac{16[f(x+1)-2f(x)+f(x-1)]-[f(x+2)-2f(x)+f(x-2)]}{12}.$$ Then using equation 1.15,
\begin{align*}
\Gamma(x+1)&=x\Gamma(x)\\
\Gamma(x+2)&=(x+1)x\Gamma(x)\\
\Gamma(x-1)&=\frac{\Gamma(x)}{x-1}\\
\Gamma(x-2)&=\frac{\Gamma(x)}{(x-1)(x-2)}.
\end{align*}

Thus, plugging in $f(x) = \log\Gamma(x)$ and using the above identities, we obtain, $$\Psi'(x)\approx \frac{1}{12}\log\left(\left(\frac{x}{x-1}\right)^{15}\left(\frac{x-2}{x+1}\right)\right).$$

b. Test Approximation 1.18 numerically as in Exercise 1.14(b). In R or Splus, `trigamma(x)` gives the value of $\Psi ' (x)$

Similar to 1.14(b), the approximation does not appear to perform well for $x$ close to 2. However, the approximation performs better for larger values of $x$.

```{r exe_1.15b}
x     <- seq(from = 2, to = 100, by = 0.01)
ratio <- 12*trigamma(x)/log((x/(x-1))^{15}*((x-2)/(x+1)))
data_1.15b <- as.data.frame(cbind(x,ratio))
library(ggplot2)
ggplot(data = data_1.15b, aes(x = x, y = ratio)) +
  geom_line() + 
  theme_minimal()
```

### Exercise 1.18
Suppose that $a_n \sim b_n$ and $c_n \sim d_n$.

a. Prove that $a_nc_n \sim b_nd_n.$

\begin{proof}
Since $a_n \sim b_n$ and $c_n \sim d_n$, then $a_n/b_n \rightarrow 1$ and $c_n/d_n \rightarrow 1$. Then $$\frac{a_nc_n}{b_nd_n} = \frac{a_n/b_n}{c_n/d_n}\rightarrow \frac{1}{1} = 1.$$ Therefore, $a_nc_n \sim b_nd_n.$
\end{proof}

b. Show by counterexample that it is not generally true that $a_n + c_n \sim b_n + d_n.$

Let $a_n = n, b_n = n + 1, c_n = -n,$ and $d_n = -n.$ Then $\frac{a_n}{b_n} = \frac{n}{n+1} \rightarrow 1$ and $\frac{c_n}{d_n} = \frac{-n}{-n} \rightarrow 1.$ Therefore, $a_n \sim b_n$ and $c_n \sim d_n$. However, $$\frac{a_n + c_n}{b_n + d_n}=\frac{n-n}{n+1-n} = 0/1 \rightarrow 0.$$ Thus, $a_n + c_n \sim b_n + d_n$ does not hold.

c. Prove that $|a_n| + |c_n| \sim |b_n| + |d_n|.$

\begin{proof}
Since $a_n \sim b_n$ and $c_n \sim d_n$, $\left|\frac{a_n-b_n}{a_n}\right|\rightarrow 0$ and $\left|\frac{c_n-d_n}{c_n}\right|\rightarrow 0$. Then

\begin{align*}
\left|\frac{(|a_n|+|c_n|)-(|b_n|+|d_n|)}{|a_n|+|c_n|}\right| & = \left|\frac{(|a_n|-|b_n|)+(|c_n|-|d_n|)}{|a_n|+|c_n|}\right|\\
& = \left|\left(\frac{|a_n|}{|a_n|+|c_n|}\right)\left(\frac{|a_n|-|b_n|}{|a_n|}\right)+\left(\frac{|c_n|}{|a_n|+|c_n|}\right)\left(\frac{|c_n|-|d_n|}{|c_n|}\right)\right|\\
& \rightarrow C_1\cdot 0 + C_2 \cdot 0\\
& = 0.
\end{align*}

Thus, since $$\left|\frac{(|a_n|+|c_n|)-(|b_n|+|d_n|)}{|a_n|+|c_n|}\right|\rightarrow 0,$$
$|a_n| + |c_n| \sim |b_n| + |d_n|.$
\end{proof}

d. Show by counterexample that it is not generally true that $f(a_n) \sim f(b_n)$ for a continuous function $f(x)$.

Let $a_n = n^2+n$ and $b_n = n^2$. Consider $f(x) = e^x.$ Then $\frac{a_n}{b_n} = \frac{n^2+n}{n^2}\rightarrow 1$, but $\frac{e^{n^2+n}}{e^{n^2}} = e^x \rightarrow \infty.$ Therefore, $f(a_n) \sim f(b_n)$ does not hold.